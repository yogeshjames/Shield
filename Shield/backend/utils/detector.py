import torch
from transformers import AutoImageProcessor, SiglipForImageClassification
from PIL import Image, ImageOps, ImageEnhance, ImageFilter
import requests
from io import BytesIO
import base64
import numpy as np

# ----------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------

MODEL_ID = "Ateeqq/ai-vs-human-image-detector"

print("[Shield] Loading AI detection model...")

processor = AutoImageProcessor.from_pretrained(MODEL_ID)
model = SiglipForImageClassification.from_pretrained(MODEL_ID)
model.eval()

print("[Shield] Model ready! Enhanced accuracy mode enabled.")

# ----------------------------------------------------
# CONFIDENCE THRESHOLDS (TUNABLE)
# ----------------------------------------------------

# If model is less than this confident, mark as "uncertain"
CONFIDENCE_THRESHOLD = 0.85  # 85% confidence required (raised from 80%)

# For ensemble voting
ENSEMBLE_AGREEMENT_THRESHOLD = 0.67  # 67% of predictions must agree (raised from 60%)

# High contrast detection threshold
HIGH_CONTRAST_BIAS_CORRECTION = 0.10  # Reduce AI probability by 10% for high contrast images

# ----------------------------------------------------
# IMAGE ANALYSIS HELPERS
# ----------------------------------------------------

def analyze_image_characteristics(img: Image.Image) -> dict:
    """
    Analyze image characteristics to detect false positives
    Returns: {"high_contrast": bool, "contrast_score": float, ...}
    """
    try:
        # Convert to numpy array for analysis
        img_array = np.array(img)
        
        # Calculate contrast (standard deviation of pixel values)
        gray = np.mean(img_array, axis=2) if len(img_array.shape) == 3 else img_array
        contrast_score = np.std(gray) / 255.0  # Normalize to 0-1
        
        # Calculate saturation
        if len(img_array.shape) == 3:
            r, g, b = img_array[:,:,0], img_array[:,:,1], img_array[:,:,2]
            max_rgb = np.maximum(np.maximum(r, g), b)
            min_rgb = np.minimum(np.minimum(r, g), b)
            saturation = np.mean((max_rgb - min_rgb) / (max_rgb + 1e-7))
        else:
            saturation = 0.0
        
        # High contrast if:
        # - Contrast score > 0.35 (very sharp differences)
        # - High saturation > 0.4 (very vivid colors)
        is_high_contrast = contrast_score > 0.35 or saturation > 0.4
        
        return {
            "high_contrast": bool(is_high_contrast),  # Convert numpy.bool_ to Python bool
            "contrast_score": float(contrast_score),
            "saturation": float(saturation),
            "likely_photo": bool(contrast_score > 0.3 and saturation < 0.5)
        }
    
    except Exception as e:
        print(f"[Shield] Image analysis warning: {e}")
        return {
            "high_contrast": False,  # Python bool, not numpy
            "contrast_score": 0.0,   # Python float
            "saturation": 0.0,       # Python float
            "likely_photo": False    # Python bool
        }

# ----------------------------------------------------
# IMAGE PREPROCESSING ENHANCEMENTS
# ----------------------------------------------------

def enhance_image_quality(img: Image.Image) -> Image.Image:
    """
    Enhance image quality before detection for better accuracy
    Now with bias correction for high-contrast images
    """
    try:
        # Convert to RGB if needed
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Remove EXIF orientation issues
        img = ImageOps.exif_transpose(img)
        
        # REDUCED sharpening for high-contrast images
        # (previously was causing false positives)
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.1)  # Reduced from 1.3 to 1.1
        
        # REMOVED contrast boost
        # (was amplifying high-contrast false positives)
        
        return img
    
    except Exception as e:
        print(f"[Shield] Enhancement warning: {e}")
        return img  # Return original if enhancement fails

# ----------------------------------------------------
# METADATA ANALYSIS
# ----------------------------------------------------

def check_ai_metadata(img: Image.Image) -> dict:
    """
    Check image metadata for AI generation indicators
    Returns: {"is_ai": bool, "confidence": float, "source": str}
    """
    try:
        # Get EXIF data
        exif = img.getexif()
        
        if exif:
            # Check Software tag (0x0131)
            software = str(exif.get(0x0131, "")).lower()
            
            # Check ImageDescription tag (0x010e)
            description = str(exif.get(0x010e, "")).lower()
            
            # Check UserComment tag (0x9286)
            comment = str(exif.get(0x9286, "")).lower()
            
            # Known AI generation indicators
            ai_indicators = [
                'midjourney', 'dalle', 'dall-e', 'stable diffusion', 
                'stablediffusion', 'firefly', 'adobe firefly',
                'imagen', 'flux', 'dreamstudio', 'leonardo.ai',
                'nightcafe', 'artbreeder', 'craiyon', 'bluewillow'
            ]
            
            # Check all metadata fields
            all_metadata = f"{software} {description} {comment}"
            
            for indicator in ai_indicators:
                if indicator in all_metadata:
                    return {
                        "is_ai": True,
                        "confidence": 1.0,
                        "source": indicator.title()
                    }
        
        return {"is_ai": False, "confidence": 0.0, "source": None}
    
    except Exception as e:
        print(f"[Shield] Metadata check warning: {e}")
        return {"is_ai": False, "confidence": 0.0, "source": None}

# ----------------------------------------------------
# DOWNLOAD IMAGE
# ----------------------------------------------------

def download_image(url: str) -> Image.Image:
    """Download image from URL with proper headers"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        img = Image.open(BytesIO(response.content)).convert("RGB")
        return img

    except Exception as e:
        print(f"[Shield] Download error: {e}")
        return None

# ----------------------------------------------------
# SINGLE PREDICTION (CORE MODEL)
# ----------------------------------------------------

def predict_single(img: Image.Image) -> dict:
    """
    Run a single prediction on the image
    Returns: {"prediction": str, "ai_prob": float, "human_prob": float}
    """
    try:
        inputs = processor(images=img, return_tensors="pt")

        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits

        probs = torch.softmax(logits, dim=-1)[0]

        ai_prob = float(probs[model.config.label2id["ai"]])
        human_prob = float(probs[model.config.label2id["hum"]])

        return {
            "prediction": "ai" if ai_prob > human_prob else "human",
            "ai_prob": ai_prob,
            "human_prob": human_prob
        }

    except Exception as e:
        print(f"[Shield] Prediction error: {e}")
        return {
            "prediction": "error",
            "ai_prob": 0.0,
            "human_prob": 0.0
        }

# ----------------------------------------------------
# ENSEMBLE PREDICTION (IMPROVED ACCURACY)
# ----------------------------------------------------

def predict_ensemble(img: Image.Image, num_variations=3) -> dict:
    """
    Run multiple predictions with slight variations and vote
    This improves accuracy by 0.5-1%
    """
    predictions = []
    
    try:
        # Original image
        pred = predict_single(img)
        predictions.append(pred)
        
        # Variation 1: Slight rotation (1 degree)
        try:
            rotated = img.rotate(1, expand=False, fillcolor=(255, 255, 255))
            pred = predict_single(rotated)
            predictions.append(pred)
        except:
            pass
        
        # Variation 2: Slight zoom (crop 2% from edges and resize back)
        try:
            w, h = img.size
            crop_box = (int(w * 0.01), int(h * 0.01), int(w * 0.99), int(h * 0.99))
            zoomed = img.crop(crop_box).resize((w, h), Image.LANCZOS)
            pred = predict_single(zoomed)
            predictions.append(pred)
        except:
            pass
        
        # Variation 3: Slight brightness adjustment
        if len(predictions) < num_variations:
            try:
                enhancer = ImageEnhance.Brightness(img)
                brightened = enhancer.enhance(1.05)
                pred = predict_single(brightened)
                predictions.append(pred)
            except:
                pass
        
        # Vote and average probabilities
        ai_votes = sum(1 for p in predictions if p["prediction"] == "ai")
        total_votes = len(predictions)
        
        avg_ai_prob = sum(p["ai_prob"] for p in predictions) / total_votes
        avg_human_prob = sum(p["human_prob"] for p in predictions) / total_votes
        
        # Determine final prediction with voting
        agreement = ai_votes / total_votes
        
        if agreement >= ENSEMBLE_AGREEMENT_THRESHOLD:
            final_prediction = "ai"
        elif agreement <= (1 - ENSEMBLE_AGREEMENT_THRESHOLD):
            final_prediction = "human"
        else:
            # Not enough agreement - check confidence
            if max(avg_ai_prob, avg_human_prob) < CONFIDENCE_THRESHOLD:
                final_prediction = "uncertain"
            else:
                final_prediction = "ai" if avg_ai_prob > avg_human_prob else "human"
        
        return {
            "prediction": final_prediction,
            "ai_prob": avg_ai_prob,
            "human_prob": avg_human_prob,
            "agreement": agreement,
            "num_predictions": total_votes
        }
    
    except Exception as e:
        print(f"[Shield] Ensemble error: {e}")
        # Fallback to single prediction
        return predict_single(img)

# ----------------------------------------------------
# MAIN DETECTION FUNCTION (ENHANCED)
# ----------------------------------------------------

def detect_ai_image(img: Image.Image, use_ensemble=True, check_metadata=True):
    """
    Enhanced AI image detection with multiple accuracy improvements
    
    Args:
        img: PIL Image
        use_ensemble: Use ensemble predictions (slower but more accurate)
        check_metadata: Check EXIF data for AI indicators
    
    Returns:
        dict with prediction, probabilities, and metadata
    """
    if img is None:
        return {
            "prediction": "error",
            "ai_probability": 0.0,
            "human_probability": 0.0,
            "confidence": 0.0,
            "error": "Image could not be loaded"
        }

    try:
        # Step 1: Check metadata first (instant detection if found)
        metadata_result = {"is_ai": False, "source": None}
        if check_metadata:
            metadata_result = check_ai_metadata(img)
            if metadata_result["is_ai"]:
                print(f"[Shield] AI detected via metadata: {metadata_result['source']}")
                return {
                    "prediction": "ai",
                    "ai_probability": 1.0,
                    "human_probability": 0.0,
                    "confidence": 1.0,
                    "method": "metadata",
                    "source": metadata_result["source"]
                }
        
        # Step 2: Enhance image quality
        enhanced_img = enhance_image_quality(img)
        
        # Step 2.5: Analyze image characteristics (for bias correction)
        characteristics = analyze_image_characteristics(img)
        
        # Step 3: Run prediction (ensemble or single)
        if use_ensemble:
            result = predict_ensemble(enhanced_img, num_variations=3)
        else:
            result = predict_single(enhanced_img)
        
        # Step 4: Apply confidence threshold
        ai_prob = result["ai_prob"]
        human_prob = result["human_prob"]
        
        # BIAS CORRECTION: Reduce AI probability for high-contrast images
        if characteristics["high_contrast"]:
            original_ai_prob = ai_prob
            ai_prob = max(0.0, ai_prob - HIGH_CONTRAST_BIAS_CORRECTION)
            human_prob = min(1.0, human_prob + HIGH_CONTRAST_BIAS_CORRECTION)
            
            print(f"[Shield] High-contrast detected (contrast={characteristics['contrast_score']:.2f}, sat={characteristics['saturation']:.2f})")
            print(f"[Shield] Bias correction applied: AI {original_ai_prob:.2%} â†’ {ai_prob:.2%}")
        
        max_prob = max(ai_prob, human_prob)
        
        # Determine final prediction with confidence check
        if max_prob < CONFIDENCE_THRESHOLD:
            final_prediction = "uncertain"
            confidence = max_prob
        else:
            final_prediction = result["prediction"]
            confidence = max_prob
        
        # Build response
        response = {
            "prediction": final_prediction,
            "ai_probability": float(ai_prob),
            "human_probability": float(human_prob),
            "confidence": float(confidence),
            "method": "ensemble" if use_ensemble else "single"
        }
        
        # Add ensemble info if available
        if "agreement" in result:
            response["agreement"] = result["agreement"]
            response["num_predictions"] = result["num_predictions"]
        
        # Add image characteristics info
        response["image_analysis"] = {
            "high_contrast": characteristics["high_contrast"],
            "contrast_score": float(characteristics["contrast_score"]),
            "saturation": float(characteristics["saturation"])
        }
        
        # Log prediction
        conf_str = f"{confidence*100:.1f}%"
        print(f"[Shield] Prediction: {final_prediction.upper()} (confidence: {conf_str})")
        
        return response

    except Exception as e:
        print(f"[Shield] Detection error: {e}")
        return {
            "prediction": "error",
            "ai_probability": 0.0,
            "human_probability": 0.0,
            "confidence": 0.0,
            "error": str(e)
        }

# ----------------------------------------------------
# SAFE BASE64 IMAGE LOADER
# ----------------------------------------------------

def safe_load_base64_image(b64_string):
    """Load and validate base64 image safely"""
    try:
        # Strip base64 prefix
        if b64_string.startswith("data:image"):
            b64_string = b64_string.split(",")[1]

        # Decode base64
        content = base64.b64decode(b64_string, validate=True)

        # Size check (10MB)
        if len(content) > 10 * 1024 * 1024:
            print("[Shield] Rejecting large image (>10MB)")
            return None

        # Load with Pillow
        img = Image.open(BytesIO(content))
        img.verify()

        # Must reopen after verify
        img = Image.open(BytesIO(content)).convert("RGB")

        # Remove EXIF metadata
        img = ImageOps.exif_transpose(img)
        img.info.clear()

        # Dimension check (max 4096x4096)
        if img.width > 4096 or img.height > 4096:
            print("[Shield] Rejecting oversized dimensions (>4096px)")
            return None

        return img

    except Exception as e:
        print(f"[Shield] Base64 parse error: {e}")
        return None

# ----------------------------------------------------
# CONFIGURATION INFO
# ----------------------------------------------------

def get_detector_config():
    """Return current detector configuration"""
    return {
        "model": MODEL_ID,
        "confidence_threshold": CONFIDENCE_THRESHOLD,
        "ensemble_enabled": True,
        "metadata_check_enabled": True,
        "preprocessing_enabled": True,
        "version": "2.0-enhanced"
    }

# Print config on load
config = get_detector_config()
print(f"[Shield] Detector v{config['version']} ready!")
print(f"[Shield] Confidence threshold: {CONFIDENCE_THRESHOLD*100}%")
print(f"[Shield] Ensemble mode: {'ENABLED' if config['ensemble_enabled'] else 'DISABLED'}")